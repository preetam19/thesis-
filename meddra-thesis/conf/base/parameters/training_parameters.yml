training_parameters:
  cols: ["soc", "pt", "llt"]
  batch_size : 512
  tokenizer_path: "bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12"
  learning_rate : 0.00003
  save_model_path: data/06_models/trained_model.pt
soc_model:
  path: "bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12"
  model_name: 'soc'
  epochs: 0

pt_model:
  path: "bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12"
  model_name: 'pt'
  epochs: 0
  complexity: 1
llt_model:
  path: "bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12"
  model_name: 'llt'
  epochs: 0
  complexity: 1